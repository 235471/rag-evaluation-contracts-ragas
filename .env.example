GOOGLE_API_KEY = "KEY"
LANGSMITH_API_KEY = "KEY"
LANGSMITH_TRACING = true
PINECONE_API_KEY = "KEY"
PINECONE_INDEX = "INDEX"
PINECONE_CLOUD = "aws"
PINECONE_REGION = "us-east-1"
PINECONE_METRIC = "cosine"
PINECONE_DIMENSION = "3072"
GROQ_API_KEY = "KEY"
PPLX_API_KEY = "KEY"
POSTGRES_URL = "YOUR_DB_URL"
POSTGRES_TABLE_NAME = "documents_embeddings_gemini"
VECTORSTORE_BACKEND = "postgres"
LLM_PROVIDER = "gemini"
EMBEDDING_PROVIDER = "gemini"
LOG_LEVEL = "INFO"
LANGSMITH_PROJECT="YOUR_PROJECT"

# Semantic Cache
CACHE_TABLE_NAME = "semantic_cache"
CACHE_SIMILARITY_THRESHOLD = "0.92"
CACHE_EMBEDDING_DIMENSION = "768"  # 768 or 1536 (Gemini Matryoshka truncation)

# Adaptive Chunking Configuration
# Optional: Specify a full model name to use its optimal tokenizer and context window
# EMBEDDING_MODEL = "gemini-embedding-001" 
# Manual overrides (leave unset to use model defaults):
# CHUNK_SIZE = "1500"
# CHUNK_OVERLAP = "150"
# CHUNKING_TOKENIZER = "tiktoken:cl100k_base"